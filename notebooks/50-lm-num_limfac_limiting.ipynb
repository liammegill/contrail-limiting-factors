{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf1fe473-04e2-45df-9d35-fd202eafacd6",
   "metadata": {},
   "source": [
    "# Limiting factors (non-border) analysis\n",
    "\n",
    "_Dataset:_ Supplementary data for Megill and Grewe (2024): \"Investigating the limiting aircraft design-dependent and environmental factors of persistent contrail formation\".\n",
    "\n",
    "_Authors:_\n",
    "\n",
    "- Liam Megill (1, 2), https://orcid.org/0000-0002-4199-6962   \n",
    "- Volker Grewe (1, 2), https://orcid.org/0000-0002-8012-6783  \n",
    "\n",
    "_Affiliation (1)_: Deutsches Zentrum für Luft- und Raumfahrt (DLR), Institut für Physik der Atmosphäre, Oberpfaffenhofen, Germany\n",
    "\n",
    "_Affiliation (2)_: Delft University of Technology (TU Delft), Faculty of Aerospace Engineering, Section Aircraft Noise and Climate Effects (ANCE), Delft, The Netherlands\n",
    "\n",
    "_Corresponding author_: Liam Megill, liam.megill@dlr.de\n",
    "\n",
    "_doi_: https://doi.org/10.5194/egusphere-2024-3398\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### Summary\n",
    "This notebook analyses the limiting factors of persistent contrail formation within each grid cell (not along the border). The goal is to understand the aircraft design-, altitude-, latitude- and seasonal dependence of these factors. \n",
    "\n",
    "### Inputs\n",
    "- `data/aircraft_specs_v2.nc`: Aircraft specifications created with `02-lm-create_aircraft_specs.ipynb`.\n",
    "- `data/processed/limfac/areas_grib.pickle`: Grid cell areas\n",
    "- ERA5 GRIB data: If not performing the study on DKRZ Levante, the ERA5 GRIB data needs to be saved locally and `dir_path` updated. We recommend placing the ERA5 files in `data/raw/`. Ensure Ensure that the file naming matches that of `t_file_path` and `r_file_path`.\n",
    "\n",
    "### Outputs\n",
    "- `data/processed/limfac/all/nonborder_limfac_r1M_{season_year}-{i_mon}_ERA5_GRIB_{cor_savename_ext}.nc`: Limiting factors results season-year (e.g. 2010 DJF) `season_year`, month index `i_mon` and RHi enhancement `cor_savename_ext`.\n",
    "- \n",
    "\n",
    "---\n",
    "\n",
    "### Copyright\n",
    "\n",
    "Copyright © 2024 Liam Megill\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0. Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951329f7-a29a-4806-8858-dd0e24fe605b",
   "metadata": {},
   "source": [
    "To start, set the top-level directory path `project_dir`. Then, select the starting and ending seasons. Unlike the boundary limiting factors analyses, this analysis considers all aircraft designs simultaneously. In the linked paper, a `random_seed` of 42 and `num_h_per_s` (number of hours selected per season) of 2160. The RHi enhancement (\"correction\") can be selected by modifying variables `rhi_cor` (multiplier) and `cor_savename_ext` (extension that gets added to the end of the save name). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d65881-95d8-4272-a655-c99b0818996c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import warnings\n",
    "import cf2cdm\n",
    "from collections import defaultdict\n",
    "import datetime\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "# options\n",
    "random_seed = 42  # seed for np.random\n",
    "num_h_per_s = 2160  # total number of random hours per season (DJF, MAM, JJA, SON)\n",
    "starting_season = \"2013DJF\"\n",
    "ending_season = \"2014SON\"  # inclusive!\n",
    "\n",
    "# define directories\n",
    "project_dir = \"\"  # set top-level directory path\n",
    "processed_data_dir = project_dir + \"data/processed/limfac/\"\n",
    "\n",
    "# correction\n",
    "rhi_cor = 0.98  # correction to RHi\n",
    "cor_savename_ext = \"cor-98p\"  # this gets added to the end of the savename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25814f8-1244-4639-952f-0cefcb53e484",
   "metadata": {},
   "source": [
    "The first step is to select the random hours within the 2010 decade that will be analysed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7bed51-c286-40a0-aa10-abac248a2ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import select_random_hours, get_season_year, generate_season_years\n",
    "\n",
    "# select, sort and group dates by season-year\n",
    "selected_hours = select_random_hours(num_h_per_s, seed=random_seed) \n",
    "all_selected_hours = np.concatenate(selected_hours)  # flatten across seasons\n",
    "all_selected_hours.sort()  # sort by datetime\n",
    "all_selected_hours = pd.to_datetime(all_selected_hours)  # convert to pandas for easier manipulation\n",
    "season_year_to_dates = defaultdict(list)\n",
    "for hour in all_selected_hours:  # group by season-year\n",
    "    season_year = get_season_year(hour)\n",
    "    season_year_to_dates[season_year].append(hour)\n",
    "\n",
    "# create full list of season-years\n",
    "all_season_years = generate_season_years(2010, 2019)\n",
    "starting_season_idx = all_season_years.index(starting_season)\n",
    "ending_season_idx = all_season_years.index(ending_season)\n",
    "season_years = all_season_years[starting_season_idx:ending_season_idx+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5a73c1-2a44-42db-bd99-5ec2e1f43f2b",
   "metadata": {},
   "source": [
    "The next step is to calculate the limiting factors. We start by loading `areas`, which are required by the main function. Next, we run through each day within each `season_year`, load the ERA5 data from file, select relevant hours and then run the limiting factors function `calc_limfacs_nonborder`. We concatenate the results of each day into `dsg_mon`, normalise the results and then save the resulting `dsg_sum` to file. To save memory, we save the results per month (rather than per season) and remove `dsg_season` and `dsg_sum` after each loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51a3018-9b8c-4fd5-89aa-943c190dbf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import calc_limfacs_nonborder\n",
    "\n",
    "# load areas\n",
    "with open(processed_data_dir+\"areas_grib.pickle\", \"rb\") as f:\n",
    "    areas = pickle.load(f)\n",
    "\n",
    "ac_ids = [\"AC8\", \"AC7\", \"AC3\", \"AC0\", \"AC1\", \"AC4\"]\n",
    "ac_full = xr.load_dataset(project_dir+\"data/aircraft_specs_v2.nc\")\n",
    "\n",
    "for season_year in season_years:\n",
    "    start_time = time.time()\n",
    "    if season_year != season_years[0]:\n",
    "        time_info = f\"Time of last season-year calculation: {d_time}\"\n",
    "    else:\n",
    "        time_info = \"\"\n",
    "    print(f\"Processing season-year: {season_year}. {time_info}\")\n",
    "    datetimes = season_year_to_dates[season_year]\n",
    "    datetimes = pd.to_datetime(datetimes)\n",
    "    unique_dates = pd.Series(datetimes).dt.date.unique()\n",
    "\n",
    "    # calculate and save results per month to limit RAM use\n",
    "    for i_mon in range(3):\n",
    "        print(f\"Month index {i_mon}\")\n",
    "        mon_num = seasons[season_year[-3:]][i_mon]\n",
    "        date_mon_idxs = [d.month == mon_num for d in unique_dates]\n",
    "        mon_unique_dates = unique_dates[date_mon_idxs]\n",
    "\n",
    "        for idx, date in enumerate(mon_unique_dates):\n",
    "            date_str = date.strftime(\"%Y-%m-%d\")\n",
    "            dir_path = \"/pool/data/ERA5/E5/pl/an/1H/\" \n",
    "            t_file_path = f\"{dir_path}130/E5pl00_1H_{date_str}_130.grb\"  # temperature file (130)\n",
    "            r_file_path = f\"{dir_path}157/E5pl00_1H_{date_str}_157.grb\"  # relative humidity file (157)\n",
    "            \n",
    "            # load and merge dataset dsg\n",
    "            dsg_t = xr.open_dataset(t_file_path, engine=\"cfgrib\", backend_kwargs={\"indexpath\": None})\n",
    "            dsg_r = xr.open_dataset(r_file_path, engine=\"cfgrib\", backend_kwargs={\"indexpath\": None})\n",
    "            dsg = xr.merge([dsg_t, dsg_r])\n",
    "            with warnings.catch_warnings():  # ignoring UserWarning from cf2cdm when converting coordinate time -> time\n",
    "                warnings.simplefilter('ignore')\n",
    "                dsg = cf2cdm.translate_coords(dsg, cf2cdm.ECMWF)  # convert to ECMWF coordinates\n",
    "            dsg = dsg.isel(level=[18, 19, 20, 21, 22, 23, 24])  # selecting only the levels that are interesting\n",
    "            \n",
    "            # extract relevant hours for the current date and filter dsg\n",
    "            hours_for_date = [hour for hour in datetimes if hour.date() == date]\n",
    "            relevant_times = pd.to_datetime(hours_for_date)\n",
    "            dsg = dsg.sel(time=relevant_times)\n",
    "            \n",
    "            # calculate limiting factors and concatenate across season\n",
    "            res = calc_limfacs_nonborder(dsg, ac_full, ac_ids, rhi_cor)\n",
    "            res = res.assign_coords(time=date)\n",
    "            if idx == 0:\n",
    "                dsg_mon = res\n",
    "            else:\n",
    "                dsg_mon = xr.concat([dsg_mon, res], dim=\"time\")\n",
    "\n",
    "\n",
    "        # sum and save dataset\n",
    "        mon_len_datetimes = sum(datetimes.month == mon_num)\n",
    "        dsg_sum = dsg_mon.sum(dim=\"time\") / mon_len_datetimes\n",
    "        dsg_sum = dsg_sum.assign(n_time=mon_len_datetimes)\n",
    "        dsg_sum.attrs.update({\"author\": \"Liam Megill\",\n",
    "                              \"institution\": \"Deutsches Zentrum für Luft- und Raumfahrt, Institute of Atmospheric Physics\",\n",
    "                              \"description\": \"Monthly non-border contrail limiting factors, calculated using random hours within the 2010 decade of ERA5 GRIB data stored on DKRZ Levante\",\n",
    "                              \"seed\": random_seed,\n",
    "                              \"aircraft_ids\": ac_ids,\n",
    "                              \"timespan\": f\"{season_year}\",\n",
    "                              \"n_time\": mon_len_datetimes,\n",
    "                              \"created\": \"{} CET\".format(datetime.datetime.today().strftime(\"%Y-%m-%d %H:%M:%S\")),\n",
    "                              \"corrections\": \"None\"})\n",
    "    \n",
    "        savename = f\"{processed_data_dir}all/nonborder_limfac_r1M_{season_year}-{i_mon}_ERA5_GRIB_{cor_savename_ext}.nc\"\n",
    "        dsg_sum.to_netcdf(savename)\n",
    "\n",
    "        # save memory\n",
    "        del dsg_sum\n",
    "        del dsg_mon\n",
    "\n",
    "    end_time = time.time()\n",
    "    d_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9bfbc5-7551-4b1a-9fcd-e2598480b8d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "1 Python 3 (based on the module python3/2023.01)",
   "language": "python",
   "name": "python3_2023_01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
