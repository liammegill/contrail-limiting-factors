{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cfa2cc0-bbcf-4f38-9721-1aa5970cbf30",
   "metadata": {},
   "source": [
    "# Horizontal limiting factors analysis\n",
    "\n",
    "_Dataset:_ Supplementary data for Megill and Grewe (2024): \"Investigating the limiting aircraft design-dependent and environmental factors of persistent contrail formation\".\n",
    "\n",
    "_Authors:_\n",
    "\n",
    "- Liam Megill (1, 2), https://orcid.org/0000-0002-4199-6962   \n",
    "- Volker Grewe (1, 2), https://orcid.org/0000-0002-8012-6783  \n",
    "\n",
    "_Affiliation (1)_: Deutsches Zentrum für Luft- und Raumfahrt (DLR), Institut für Physik der Atmosphäre, Oberpfaffenhofen, Germany\n",
    "\n",
    "_Affiliation (2)_: Delft University of Technology (TU Delft), Faculty of Aerospace Engineering, Section Aircraft Noise and Climate Effects (ANCE), Delft, The Netherlands\n",
    "\n",
    "_Corresponding author_: Liam Megill, liam.megill@dlr.de\n",
    "\n",
    "_doi_: https://doi.org/10.5194/egusphere-2024-3398\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### Summary\n",
    "This notebook analyses the horizontal limiting factors of persistent contrail formation using ERA5 data. It randomly generates hours within the 2010 decade, performs the analysis between `starting_season` and `ending_season` and saves the results.\n",
    "\n",
    "### Inputs\n",
    "- `data/aircraft_specs_v2.nc`: Aircraft specifications created with `02-lm-create_aircraft_specs.ipynb`.\n",
    "- `data/processed/limfac/neighbors_grib.pickle`: Horizontal grid cell neighbors\n",
    "- `data/processed/limfac/perimeters_grib.pickle`: Horizontal grid cell perimeters\n",
    "- ERA5 GRIB data: If not performing the study on DKRZ Levante, the ERA5 GRIB data needs to be saved locally and `dir_path` updated. We recommend placing the ERA5 files in `data/raw/`. Ensure Ensure that the file naming matches that of `t_file_path` and `r_file_path`.\n",
    "\n",
    "### Outputs\n",
    "- `data/processed/limfac/AC*/limfac_{ac_id}_r1S_{season_year}_ERA5_GRIB_{cor_savename_ext}.nc`: Limiting factors results for aircraft `ac_id`, season-year (e.g. 2010 DJF) `season_year` and RHi enhancement `cor_savename_ext`. The results are saved into a subfolder `AC*` which corresponds to `ac_id`.\n",
    "\n",
    "---\n",
    "\n",
    "### Copyright\n",
    "\n",
    "Copyright © 2024 Liam Megill\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0. Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ccaa1f-b781-4c6f-9b6e-bb9e8d7f8825",
   "metadata": {},
   "source": [
    "To start, set the top-level directory path `project_dir`. Then, select the starting and ending seasons and the aircraft design to be analysed. In the linked paper, a `random_seed` of 42 and `num_h_per_s` (number of hours selected per season) of 2160. The RHi enhancement (\"correction\") can be selected by modifying variables `rhi_cor` (multiplier) and `cor_savename_ext` (extension that gets added to the end of the save name). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec63cd4a-6815-450a-b17b-3fb581fce19e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load modules\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import cf2cdm\n",
    "from collections import defaultdict\n",
    "import datetime\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "# options\n",
    "random_seed = 42  # seed for np.random\n",
    "num_h_per_s = 2160  # total number of random hours per season (DJF, MAM, JJA, SON)\n",
    "starting_season = \"2010DJF\"\n",
    "ending_season = \"2014SON\"  # inclusive!\n",
    "\n",
    "##### if testing!! ######\n",
    "test_savename_ext = False  # this adds the \"test\" flag to the savename\n",
    "\n",
    "# define directories\n",
    "project_dir = \"\"  # set top-level directory path\n",
    "processed_data_dir = project_dir + \"data/processed/limfac/\"\n",
    "\n",
    "# load aircraft\n",
    "ac_id = \"AC0\"  # choice of aircraft - matches ac_id in ac dataset\n",
    "ac = xr.load_dataset(project_dir+\"data/aircraft_specs_v2.nc\").sel(id=ac_id)\n",
    "\n",
    "# correction\n",
    "rhi_cor = 1.0  # correction to RHi\n",
    "cor_savename_ext = \"uncor\"  # this gets added to the end of the savename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc99cc9-c0b3-4eaf-bdad-8349cb10d3b7",
   "metadata": {},
   "source": [
    "The first step is to select the random hours within the 2010 decade that will be analysed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2425119f-fc76-4349-bdec-8ddc1f533c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select random hours to analyse\n",
    "from helper import select_random_hours, get_season_year, generate_season_years\n",
    "\n",
    "# select, sort and group dates by season-year\n",
    "selected_hours = select_random_hours(num_h_per_s, seed=random_seed) \n",
    "all_selected_hours = np.concatenate(selected_hours)  # flatten across seasons\n",
    "all_selected_hours.sort()  # sort by datetime\n",
    "all_selected_hours = pd.to_datetime(all_selected_hours)  # convert to pandas for easier manipulation\n",
    "season_year_to_dates = defaultdict(list)\n",
    "for hour in all_selected_hours:  # group by season-year\n",
    "    season_year = get_season_year(hour)\n",
    "    season_year_to_dates[season_year].append(hour)\n",
    "\n",
    "# create full list of season-years\n",
    "all_season_years = generate_season_years(2010, 2019)\n",
    "starting_season_idx = all_season_years.index(starting_season)\n",
    "ending_season_idx = all_season_years.index(ending_season)\n",
    "season_years = all_season_years[starting_season_idx:ending_season_idx+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844681c7-a988-4e17-8659-9a8784e2bcc3",
   "metadata": {},
   "source": [
    "The next step is to calculate the limiting factors. We start by loading `neighbors` and `perimeters`, which are required by the main function. Next, we run through each day within each `season_year`, load the ERA5 data from file, select relevant hours and then run the limiting factors function `calc_limfacs_rnd`. We concatenate the results of each day into `dsg_season`, normalise the results and then save the resulting `dsg_sum` to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e976ce4-c1c6-473f-a9d5-1afb1dc34f9b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import functions\n",
    "from helper import calc_limfacs_rnd\n",
    "\n",
    "# load neighbors and perimeters\n",
    "with open(processed_data_dir+\"neighbors_grib.pickle\", \"rb\") as f:\n",
    "    neighbors = pickle.load(f)\n",
    "with open(processed_data_dir+\"perimeters_grib.pickle\", \"rb\") as f:\n",
    "    perimeters_dict = pickle.load(f)\n",
    "perimeters = np.array(list(perimeters_dict.values()))  # convert to 1D array for normalisation\n",
    "\n",
    "# loop through each season-year and process relevant hours\n",
    "for season_year in season_years:\n",
    "    \n",
    "    # print time taken to run each step in the loop\n",
    "    start_time = time.time()\n",
    "    if season_year != season_years[0]:\n",
    "        time_info = f\"Time of last season-year calculation: {d_time}\"\n",
    "    else:\n",
    "        time_info = \"\"\n",
    "    print(f\"Processing season-year: {season_year}. {time_info}\")\n",
    "\n",
    "    # find unique dates within season_year\n",
    "    dates = season_year_to_dates[season_year]\n",
    "    dates = pd.to_datetime(dates)\n",
    "    unique_dates = pd.Series(dates).dt.date.unique()\n",
    "\n",
    "    # for loop over all unique dates within season-year\n",
    "    for idx, date in enumerate(unique_dates):\n",
    "        date_str = date.strftime(\"%Y-%m-%d\")\n",
    "        dir_path = \"/pool/data/ERA5/E5/pl/an/1H/\" \n",
    "        t_file_path = f\"{dir_path}130/E5pl00_1H_{date_str}_130.grb\"  # temperature file (130)\n",
    "        r_file_path = f\"{dir_path}157/E5pl00_1H_{date_str}_157.grb\"  # relative humidity file (157)\n",
    "    \n",
    "        try:\n",
    "            # load and merge dataset dsg\n",
    "            dsg_t = xr.open_dataset(t_file_path, engine=\"cfgrib\", backend_kwargs={\"indexpath\": None})\n",
    "            dsg_r = xr.open_dataset(r_file_path, engine=\"cfgrib\", backend_kwargs={\"indexpath\": None})\n",
    "            dsg = xr.merge([dsg_t, dsg_r])\n",
    "            with warnings.catch_warnings():  # ignoring UserWarning from cf2cdm when converting coordinate time -> time\n",
    "                warnings.simplefilter('ignore')\n",
    "                dsg = cf2cdm.translate_coords(dsg, cf2cdm.ECMWF)  # convert to ECMWF coordinates\n",
    "            dsg = dsg.isel(level=[18, 19, 20, 21, 22, 23, 24])  # selecting only the levels that are interesting\n",
    "    \n",
    "            # extract relevant hours for the current date and filter dsg\n",
    "            hours_for_date = [hour for hour in dates if hour.date() == date]\n",
    "            relevant_times = pd.to_datetime(hours_for_date)\n",
    "            dsg = dsg.sel(time=relevant_times)\n",
    "\n",
    "            # calculate limiting factors and concatenate across season\n",
    "            res = calc_limfacs_rnd(dsg, ac, neighbors, perimeters, rhi_cor)\n",
    "            res = res.assign_coords(time=date)\n",
    "            if idx == 0:\n",
    "                dsg_season = res\n",
    "            else:\n",
    "                dsg_season = xr.concat([dsg_season, res], dim=\"time\")\n",
    "\n",
    "        # handle errors\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"File not found for date: {date_str}. Error: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred for date: {date_str}. Error: {e}\")\n",
    "\n",
    "    \n",
    "    # sum and save dataset\n",
    "    try:\n",
    "        dsg_sum = dsg_season.sum(dim=\"time\") / len(dates)  # normalise with respect to number of dates (which includes different hours)\n",
    "        dsg_sum = dsg_sum.assign(n_time=len(dates))\n",
    "        dsg_sum.attrs.update({\"author\": \"Liam Megill\",\n",
    "                              \"institution\": \"Deutsches Zentrum für Luft- und Raumfahrt, Institute of Atmospheric Physics\",\n",
    "                              \"description\": \"Seasonal contrail limiting factors, calculated using random hours within the 2010 decade of ERA5 GRIB data stored on DKRZ Levante\",\n",
    "                              \"seed\": random_seed,\n",
    "                              \"aircraft_id\": ac_id,\n",
    "                              \"timespan\": f\"{season_year}\",\n",
    "                              \"n_time\": len(dates),\n",
    "                              \"created\": \"{} CET\".format(datetime.datetime.today().strftime(\"%Y-%m-%d %H:%M:%S\")),\n",
    "                              \"corrections\": cor_savename_ext})\n",
    "\n",
    "        savename = f\"{processed_data_dir}{ac_id}/{'test_' if test_savename_ext else ''}limfac_{ac_id}_r1S_{season_year}_ERA5_GRIB_{cor_savename_ext}.nc\"\n",
    "        dsg_sum.to_netcdf(savename)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred when saving season-year {season_year}. Error: {e}\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    d_time = end_time - start_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402d6688-1de7-4abf-b04f-62ccc0f304bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "1 Python 3 (based on the module python3/2023.01)",
   "language": "python",
   "name": "python3_2023_01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
